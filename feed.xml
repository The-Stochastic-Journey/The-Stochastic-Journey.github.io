<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://the-stochastic-journey.github.io//feed.xml" rel="self" type="application/atom+xml"/><link href="https://the-stochastic-journey.github.io//" rel="alternate" type="text/html"/><updated>2025-02-17T02:24:42+00:00</updated><id>https://the-stochastic-journey.github.io//feed.xml</id><title type="html">The Stochastic Journey</title><author><name>Maitrey Patel</name></author><entry><title type="html">Ch:1 Preliminaries</title><link href="https://the-stochastic-journey.github.io//2025-02-16-preliminaries/" rel="alternate" type="text/html" title="Ch:1 Preliminaries"/><published>2025-02-16T00:00:00+00:00</published><updated>2025-02-16T00:00:00+00:00</updated><id>https://the-stochastic-journey.github.io//preliminaries</id><content type="html" xml:base="https://the-stochastic-journey.github.io//2025-02-16-preliminaries/"><![CDATA[<p>Diffusion models are fundamentally based on stochastic differential equations (SDEs), which combine deterministic dynamics with randomness. While we understand that SDEs govern how diffusion models evolve and that ordinary differential equations (ODEs) are crucial for sampling, the mathematical foundations - particularly random variables and stochastic processes - deserve careful examination.</p> <p>This blog post aims to build a rigorous understanding of these foundational concepts. We’ll explore key definitions, theorems, and derivations from <a href="https://link.springer.com/book/10.1007/978-3-642-14394-6">Chapter 2 of the Book</a>, focusing on the most essential elements while providing detailed explanations where needed. By the end, we’ll try to connect it back to diffusion models.</p> <h3>Random Variable</h3> <p><strong>Definition 1.1:</strong> If \(\Omega\) is a given set, then a \(\sigma\)-algebra \(\mathcal{F}\) on \(\Omega\) is a family \(\mathcal{F}\) of subsets of \(\Omega\) with the three key properties:</p> <ol> <li>$\phi \in \mathcal{F}$</li> <li>If \(F \in \mathcal{F}\) then \(F^c \in \mathcal{F}\), where \(F^c \in \Omega \setminus \mathcal{F}\) (complement)</li> <li>If \(A_1, A_2, \ldots \in \mathcal{F}\), then \(\bigcup_{i=1}^{\infty} A_i \in \mathcal{F}\) (countable union)</li> </ol> <p>Let $P: \mathcal{F} \rightarrow [0,1]$ be the probability on a space ($\Omega, \mathcal{F}$). Then ($\Omega, \mathcal{F}, P$) together defines the probability space. Intuitively,</p> \[P(F) = \text{the probability that the event } F \text{ occurs}\] <div class="highlighted-box" style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;"> <details> <summary>(Click to expand) Toy example</summary> Let's define our sample space \(\Omega\) as all possible outcomes when rolling a fair six-sided die:<br/> \[ \Omega = \{1, 2, 3, 4, 5, 6\} \] A \(\sigma\)-algebra \(\mathcal{F}\) is a collection of subsets of Ω that satisfies the three properties. Hence, A simple example of a \(\sigma\)-algebra is:<br/> \[ \mathcal{F}=\{\phi,\Omega,\{1,3,5\},\{2,4,6\}\} \] **Task:** Try to manually verify the above three properties. </details> </div> <p><strong>Understanding the Borel sets:</strong> We can define the smallest $\sigma$-algebra $\mathcal{H}_\mathcal{U}$ containing $\mathcal{U}$ ($\mathcal{U} \in \Omega$), then</p> \[\mathcal{H}_\mathcal{U} = \bigcap\{\mathcal{H}; \mathcal{H}~\sigma \text{-algebra of } \Omega\}.\] <p>The intersection of all $\sigma$-algebras containing $\mathcal{U}$ is itself a $\sigma$-algebra and is the smallest $\sigma$-algebra containing $\mathcal{U}$. This is called the Borel $\sigma$-algebra (i.e., $\mathcal{B} = \mathcal{H}_\mathcal{U}$) generated by $\mathcal{U}$.</p> <h3>The Stochastic Process</h3> <p><strong>Definition 1.2:</strong> A stochastic process is a parameterized collection of random variables</p> \[\{X_t\}_{t \in T}\] <p>defined on a probability space ($\Omega, \mathcal{F}, P$) and assuming values in $R^n$. Here, $T$ can be any interval [a, b] (like, in diffusion we have [0, 1000]). Utilizing this fact we can define $\omega \in \Omega$ as $\omega \rightarrow X_t(\omega)$ and $t \in T$ as $t \rightarrow X_t(\omega)$. Hence, for simplicity we can write:</p> \[(t, \omega) \rightarrow X(t, \omega)\] <p><strong>Kolmogorov’s Extension Theorem:</strong> is a fundamental result in probability theory that allows us to construct stochastic processes—random variables indexed over time—when given a consistent collection of finite-dimensional distributions.</p> <p>Intuitively, this theorem states that</p> <ol> <li>K1 (Consistency Condition) (a.k.a. Chapman-Kolmogorov equation): <ul> <li>The probability measures must be consistent under marginalization. That is, if we integrate out one of the intermediate times, the resulting probability distribution must match the lower-dimensional distribution.</li> <li>Mathematically,</li> </ul> </li> </ol> \[\int_{R^n} p(t, x, z)p(s, z, y)dz = p(t+s, x, y).\] <ol> <li>K2 (Total Probability Condition): <ul> <li>The total probability of transitioning from any initial point to any final point over all space must be 1:</li> </ul> </li> </ol> \[\int_{R^n} p(t,x,y)dy = 1, \forall t \geq 0.\] <ol> <li>Then there exists a probability space $(\Omega,\mathcal{F},P)$ and a stochastic process ${X_t}$ such that these finite distributions correspond to the probabilities of events in this space.</li> </ol> <p>This result is crucial because it guarantees that if we define random variables consistently at finite time steps, we can always extend this definition to an infinite process.</p> <div class="highlighted-box" style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;"> <summary>This theorem is modified to make it easier to understand next section. However, Theorem 2.1.5 from the book provides Measure-Theoretic Form.</summary> </div> <h3>Brownian Motion</h3> <p>Brownian motion is just an example of the observed stochastic process ($B_t(\omega)$) of the pollen grains defined using the Kolmogorov’s Extension theorem. Specifically,</p> \[p(t, x, y) = (2\pi t)^{-n/2} \cdot \exp\left(-\frac{|x-y|^2}{2t}\right), \text{ where } y \in \mathbb{R}^n, t&gt;0 \text{ and fixed } x\in \mathbb{R}^n.\] <p>Then we can define probability measure as:</p> \[v_{t_1, ..., t_k} (F_1 \times ... \times F_k) = \int_{F_1} ... \int_{F_k} p(t_1, x, y_1)p(t_2-t_1, y_1, y_2)...p(t_k-t_{k-1}, y_{k-1}, y_k)dy_1...dy_k\] <p>where, $0 \leq t_1 \leq t_2 \leq … \leq t_k$. It is worth noting that, at $t=0$ we have $p(0,x,y)dy = \delta_x(y)$.</p> <p>Let’s verify that the Brownian motion equation satisfies the key criteria of Kolmogorov’s Extension Theorem:</p> <div class="highlighted-box" style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;"> <details> <summary>(Click to expand) Let's verify that the Brownian motion equation satisfies the key criteria of Kolmogorov's Extension Theorem:</summary> <b>Step 1: (Chapman-Kolmogorov equation)</b> Let's verify that the transition probability density function satisfies the Chapman-Kolmogorov equation by substituting the Gaussian density function into K1: \[ \begin{aligned} \text{LHS} &amp;= \int_{\mathbb{R}^n} p(t,x,z)p(s,z,y)dz \\ &amp;= \int_{\mathbb{R}^n} (2\pi t)^{-n/2} \exp\left(-\frac{|x-z|^2}{2t}\right) (2\pi s)^{-n/2} \exp\left(-\frac{|z-y|^2}{2s}\right) dz \\ &amp;= (2\pi t)^{-n/2} (2\pi s)^{-n/2} \exp\left(-\frac{|x-y|^2}{2(t+s)}\right) \times \int_{R^n} exp \left(-\frac{1 (s+t)}{2(ts)}|z-\alpha|^2\right) dz \\ &amp; \quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad\quad \text{ here, } \alpha \text{ is constant w.r.t. } z\\ &amp;= p(t+s,x,y) = \text{RHS} \end{aligned} \] (Note that we skipped one extra step to further simplify the second term. If needed, comment down below and I can provide it.)<br/> <b>Step 2: (Total Probability)</b> For the total probability condition, we need to show that integrating over all possible values of y equals 1: \[ \begin{aligned} \int_{\mathbb{R}^n} p(t,x,y)dy &amp;= \int_{\mathbb{R}^n} (2\pi t)^{-n/2} \exp\left(-\frac{|x-y|^2}{2t}\right)dy \\ &amp;= 1 \end{aligned} \] This equality holds because we are integrating a properly normalized Gaussian density function. Therefore, the Brownian motion transition density satisfies both key conditions of Kolmogorov's Extension Theorem, confirming that it defines a valid stochastic process. </details> </div> <h3>Theorem 2.3: Kolmogorov's Continuity Theorem</h3> <p>Kolmogorov’s Continuity Theorem provides conditions under which a stochastic process has continuous paths. It is a fundamental result in the theory of stochastic processes and is particularly useful in the study of Brownian motion and diffusion processes.</p> <p><b>Theorem:</b> Let \(X = \{X_t : t \in T\}\) be a stochastic process. Suppose there exist constants $\alpha &gt; 0$, $\beta &gt; 0$, and $C &gt; 0$ such that for all $s, t \in T$,</p> \[\mathbb{E}[|X_t - X_s|^\alpha] \leq C |t - s|^{1 + \beta}\] <p>Then, there exists a modification of the process $X$ that has continuous paths with probability 1.</p> <p><b>Explanation:</b> The theorem essentially states that if the increments of a stochastic process satisfy a certain moment condition, then the process can be modified to have continuous paths. This is particularly important for ensuring that models like Brownian motion, which are used to describe continuous phenomena, are mathematically well-defined.</p> <p>This theorem is a cornerstone in the study of stochastic processes, providing the necessary conditions for the existence of continuous sample paths, which are crucial for modeling real-world phenomena where continuity is expected.</p> <div class="highlighted-box" style="background-color: #f8f9fa; padding: 15px; border-radius: 5px; margin: 10px 0;"> <details> <summary>(Click to expand) Please refer to the derivation by <a href="https://fabricebaudoin.blog/2012/03/26/lecture-6-the-kolmogorov-continuity-theorem/">Prof. Fabrice Baudoin</a>. Intuitive explanation is attached here.</summary> <br/> The Kolmogorov Continuity Theorem helps us understand when a stochastic process has continuous paths. Here's the intuitive idea:<br/> 1. We start by looking at the process at discrete time points (like a grid).<br/> 2. Using Chebyshev's inequality, we can show that large jumps between consecutive grid points are very unlikely:<br/> \[ \text{max}_{1\leq k \leq 2^n} \left| X_{k/2^n} - X_{k-1/2^n} \right| \geq 2^{-\gamma n} \] 3. The Borel-Cantelli lemma then helps us prove that as we make our grid finer and finer (\(n\rightarrow \infty\)), the maximum size of these jumps becomes smaller and smaller:<br/> \[ \left| X_t - X_s \right| \leq \frac{2C}{1-2^{-\gamma}}2^{-n\gamma} \] 4. This means that:<br/> - The process becomes "smoother" as we look at it more closely<br/> - Any discontinuities would have to be infinitely small<br/> - Therefore, the process must be continuous "almost" surely<br/> <br/> This is particularly important for Brownian motion, as it guarantees that particle paths are continuous - there are no sudden teleportations or jumps in the motion. </details> </div> <h3>Connections between Diffusion and Brownian motion</h3> <p>Brownian motion is a specific stochastic process that models random, continuous motion, like the movement of particles in a fluid. Brownian motion is a basic building block used in many areas, such as modeling randomness, diffusion processes, and stochastic differential equations (SDEs). It has properties like,</p> <ul> <li>Gaussian increments: Changes over time follow a normal distribution.</li> <li>Continuous paths: The motion is smooth with no jumps.</li> <li>Independent increments: Motion over different time intervals is independent.</li> </ul> <p>Diffusion models are general frameworks used to model the evolution of a system over time, incorporating randomness. Diffusion models describe a forward process that adds noise to data (like images) step by step and a reverse process that removes the noise to recover the original data.</p> <p>Importantly,</p> <ul> <li>Brownian motion is a type of diffusion process where the motion is purely random, with no deterministic drift.</li> </ul> \[dX_t = \sigma dB_t ~~~~\text{(random motion)}\] <ul> <li>Diffusion models generalize the idea of Brownian motion by including a drift term and allowing for more complex dynamics.</li> </ul> \[dX_t = f(X-t, t)dt + g(X_t, t)dB_t ~~~~\text{(generalized)}\] <h3>Conclusion</h3> <p>In this blog post, we explored fundamental concepts in probability theory and stochastic processes that form the mathematical foundation of diffusion models. We covered key ideas like probability spaces, random variables, and stochastic processes, with a particular focus on Brownian motion. We also began to see how these mathematical tools connect to modern diffusion models used in machine learning.</p> <p>While this was an introductory look at these concepts, they are essential for understanding how diffusion models work at a deeper level. As we continue through the book in future posts, we will build on these fundamentals to develop a more comprehensive understanding of diffusion models and their theoretical underpinnings.</p>]]></content><author><name>Maitreya Patel</name></author><category term="SDE101"/><summary type="html"><![CDATA[Diffusion models are fundamentally based on stochastic differential equations (SDEs), which combine deterministic dynamics with randomness. While we understand that SDEs govern how diffusion models evolve and that ordinary differential equations (ODEs) are crucial for sampling, the mathematical foundations - particularly random variables and stochastic processes - deserve careful examination.]]></summary></entry><entry><title type="html">Ch:0 Introduction</title><link href="https://the-stochastic-journey.github.io//2025-02-09-introduction/" rel="alternate" type="text/html" title="Ch:0 Introduction"/><published>2025-02-09T00:00:00+00:00</published><updated>2025-02-09T00:00:00+00:00</updated><id>https://the-stochastic-journey.github.io//introduction</id><content type="html" xml:base="https://the-stochastic-journey.github.io//2025-02-09-introduction/"><![CDATA[<p>In the realm of generative models, diffusion and flow models have rapidly emerged as transformative tools across fields. Yet, beneath their impressive applications lies a rich, often concealed, mathematical foundation—a foundation built upon stochastic processes, probability theory, and differential equations. This series is an invitation to journey beneath the surface and explore the core principles that have made these models possible.</p> <p><em>The Stochastic Journey</em> is conceived as a live, evolving series dedicated to unraveling the elegant mathematics that underpin recent advances in visual generative models. Rather than merely explaining how these models work mathematically, the focus here is to trace their lineage back to the foundational theories of stochastic calculus—delving into the origins of ideas like Brownian motion, Kolmogorov’s continuity theorem, and stochastic differential equations (SDEs). As the series progresses, each post will introduce key derivations and insights, gradually constructing a clear, intuitive, and rigorous picture of the mathematical landscape that informs modern generative techniques.</p> <p>It is all too common today to master the application of diffusion models without fully understanding the deep mathematical evolution that brought us to this moment. While many practitioners can skillfully implement these models, the intricate journey—from abstract theorems and classical proofs to the practical algorithms used in contemporary research—remains largely uncharted territory for most. This series aims to bridge that gap, revealing the profound insights that underpin our current tools and highlighting the evolution of ideas that have enabled today’s breakthroughs.</p> <p>A central reference for this exploration is <a href="https://link.springer.com/book/10.1007/978-3-642-14394-6">Stochastic Differential Equations: An Introduction with Applications by Bernt Øksendal</a>—a seminal text that provides deep insights into SDEs. Recognizing that Øksendal’s work can be challenging for those without an extensive mathematical background, this series is crafted to demystify complex ideas through detailed explanations and derivations. It is designed specifically for readers who may have a mathematical familiarity with diffusion models but seek a deeper understanding of the mathematical journey behind them.</p> <p>This work does not assume advanced prior knowledge of stochastic calculus or differential equations; instead, it is tailored for anyone eager to uncover the mathematics that paved the way for modern generative modeling. As new insights and derivations emerge, they will be shared in real time as part of this ongoing, live series. The goal is not to provide a definitive guide to diffusion or flow models, but to peel back the layers and illuminate the historical context that has led us to this technological frontier.</p> <p>Welcome to <em>The Stochastic Journey</em>. Join me as we explore the rich mathematical heritage that made these advances possible. Enjoy the exploration!</p>]]></content><author><name>Maitreya Patel</name></author><category term="SDE101"/><summary type="html"><![CDATA[In the realm of generative models, diffusion and flow models have rapidly emerged as transformative tools across fields. Yet, beneath their impressive applications lies a rich, often concealed, mathematical foundation—a foundation built upon stochastic processes, probability theory, and differential equations. This series is an invitation to journey beneath the surface and explore the core principles that have made these models possible.]]></summary></entry></feed>